{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97e9625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from art_uw import nl_program, conf_edit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe42a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool use distribution\n",
    "import parsimonious\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# tool use extraction utils\n",
    "class Node:\n",
    "    def __init__(self, expr_name, text):\n",
    "        self.expr_name = expr_name\n",
    "        self.text = text\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps({\"expr_name\": self.expr_name, \"text\": self.text}, indent=2)\n",
    "    \n",
    "    def get_content(self):\n",
    "        return {\"expr_name\": self.expr_name, \"text\": self.text}\n",
    "    \n",
    "    \n",
    "def recursive_node_visit(node, selection_criterion, node_list):\n",
    "    for child in node.children:\n",
    "        recursive_node_visit(child, selection_criterion, node_list)\n",
    "    if node.expr_name in selection_criterion:\n",
    "        node_list.append(Node(node.expr_name, node.text))\n",
    "        return\n",
    "    \n",
    "def clean_text(node: list) -> list:\n",
    "    cleaned = []\n",
    "    pattern = r\"\\[[A-Za-z_ ]+\\]\"\n",
    "    for n in node:\n",
    "        match = re.findall(pattern, n)\n",
    "        if match:\n",
    "            cleaned.extend(match)\n",
    "    return cleaned\n",
    "    \n",
    "    \n",
    "def collect_usage(df: pd.DataFrame) -> list:\n",
    "    grammar = parsimonious.grammar.Grammar(\n",
    "r\"\"\"\n",
    "program = program_start*node*partial_command*final_answer\n",
    "program_start = input_start~r\"( |\\n)\"text~r\"\\n\"\n",
    "input_start = ~r\"Input:\"\n",
    "text = ~r\"(?<=Input:( |\\n))(.|\\n|\\t)*?(?=\\nQ[0-9]+:)\"\n",
    "node = command_node~r\"\\n\"output_node~r\"\\n\"\n",
    "command_node = command_start~r\"( |\\n)\"command_instruction\n",
    "output_node = begin_answer~r\"( |\\n)\"output\n",
    "command_instruction = ~r\"(?<=\\]( |\\n))(.|\\n|\\t)*?(?=\\n\\#[0-9]+)\"\n",
    "command_start = ~r\"Q[0-9]+:[ ]+\\[[A-Za-z_ ]+\\]\"\n",
    "begin_answer = ~r\"\\#[0-9]+:\"\n",
    "output = ~r\"(?<=\\#[0-9]+:( |\\n))(.|\\n|\\t)*?(?=\\nQ[0-9]+:)\"\n",
    "partial_command = command_start~r\"\\n\"\n",
    "final_answer = ~r\"Ans:( |\\n)(.|\\n)*$\"\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "    # extract tool use from prompts\n",
    "    prompts = [p for p in df[\"after_art\"]]\n",
    "    tool_use = []\n",
    "\n",
    "    for p in prompts:\n",
    "        try:\n",
    "            parsed_program = grammar.parse(p)\n",
    "            command_nodes = parsed_program.children[1]\n",
    "            command_node_list = []\n",
    "\n",
    "            for node in command_nodes.children:\n",
    "                # Access all children and focus on getting \"command_start\", \"command_instruction\", \"begin_answer\" and \"output\"\n",
    "                child_node_list = []\n",
    "                recursive_node_visit(node, [\"command_start\", \"command_instruction\", \"begin_answer\", \"output\"], child_node_list)\n",
    "                command_node_list.append(child_node_list)\n",
    "\n",
    "            commands = [node[0].get_content()[\"text\"].lower() for node in command_node_list]\n",
    "            commands = clean_text(commands)\n",
    "            tool_use.append(commands)\n",
    "\n",
    "        except:\n",
    "            tool_use.append([])\n",
    "\n",
    "\n",
    "    usage = []\n",
    "    for each in tool_use:\n",
    "        usage.append(each)\n",
    "    \n",
    "    return usage\n",
    "\n",
    "\n",
    "def collect_conf(df: pd.DataFrame) -> list:\n",
    "    grammar = parsimonious.grammar.Grammar(\n",
    "r\"\"\"\n",
    "program = program_start*node*partial_command*final_answer\n",
    "program_start = input_start~r\"( |\\n)\"text~r\"\\n\"\n",
    "input_start = ~r\"\\n*Input:\"\n",
    "text = ~r\"(?<=Input:( |\\n))(.|\\n|\\t)*?(?=\\nQ[0-9]+:)\"\n",
    "node = command_node~r\"\\n\"output_node~r\"\\n\"\n",
    "command_node = command_start~r\"( |\\n)\"confidence_score~r\"( |\\n)\"command_instruction\n",
    "output_node = begin_answer~r\"( |\\n)\"output\n",
    "command_instruction = ~r\"(?<=[0-9]\\]( |\\n))(.|\\n|\\t)*?(?=\\n\\#[0-9]+)\"\n",
    "command_start = ~r\"Q[0-9]+:[ \\n]+\\[[A-Za-z_ ]+\\]\"\n",
    "confidence_score = ~r\"(?<=\\]( |\\n))\\[[0-9]+\\]\"\n",
    "begin_answer = ~r\"\\#[0-9]+:\"\n",
    "output = ~r\"(?<=\\#[0-9]+:( |\\n))(.|\\n|\\t)*?(?=\\nQ[0-9]+:)\"\n",
    "partial_command = command_start~r\"\\n\"\n",
    "final_answer = ~r\"Ans:( |\\n)(.|\\n)*$\"\n",
    "\"\"\")\n",
    "\n",
    "    # extract conf_score from prompts\n",
    "    prompts = [p for p in df[\"after_art\"]]\n",
    "    conf = []\n",
    "    for p in prompts:\n",
    "        try:\n",
    "            parsed_program = grammar.parse(p)\n",
    "            command_nodes = parsed_program.children[1]\n",
    "            command_node_list = []\n",
    "\n",
    "            for node in command_nodes.children:\n",
    "                # Access all children and focus on getting \"command_start\", \"command_instruction\", \"begin_answer\" and \"output\"\n",
    "                child_node_list = []\n",
    "                recursive_node_visit(node, [\"command_start\", \"confidence_score\", \"command_instruction\", \"begin_answer\", \"output\"], child_node_list)\n",
    "                command_node_list.append(child_node_list)\n",
    "                \n",
    "            commands = [node[1].get_content()[\"text\"] for node in command_node_list]\n",
    "            conf.append(commands)\n",
    "\n",
    "        except:\n",
    "            conf.append([])\n",
    "            \n",
    "    # convert '[90]' to float in conf\n",
    "    final = []\n",
    "    for c in conf:\n",
    "        if c:\n",
    "            lst = [ast.literal_eval(s)[0] for s in c]\n",
    "            final.append(np.average(np.array(lst)))\n",
    "        else:\n",
    "            final.append(0)\n",
    "    return final\n",
    "\n",
    "def jaccard_sim(actual_tool, ref_tools): # ref tools is a ndarray\n",
    "    \n",
    "    set1, set2 = set(actual_tool), [set(tool) for tool in ref_tools]\n",
    "    possible_sims = []\n",
    "    for s in set2:\n",
    "        # intersection of two sets\n",
    "        intersection = len(set1.intersection(s))\n",
    "        # Unions of two sets\n",
    "        union = len(set1.union(s))\n",
    "        possible_sims.append(intersection / union)\n",
    "    return max(possible_sims)\n",
    "\n",
    "def check_answer(row):\n",
    "    if row.prediction != \"\":\n",
    "        return (row.answer.lower() in row.prediction.lower()) or (row.prediction.lower() in row.answer.lower())\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def collect_conf_acc(f):\n",
    "    print(f\"Reading file {f}...\")\n",
    "    # read single file\n",
    "    df = pd.read_json(f)[:1000]\n",
    "    \n",
    "    # logit based conf collection\n",
    "    try:\n",
    "        output = 100*np.e**(df['logprobs'].apply(filter_tool_log))\n",
    "#         print(\"IN!!!\")\n",
    "    # verbalized conf collection\n",
    "    except:\n",
    "        output = collect_conf(df)\n",
    "\n",
    "    bins = np.linspace(0, 100, 10)\n",
    "    bin_indices = np.digitize(output, bins=bins)\n",
    "\n",
    "    df[\"adj_correct\"] = df.apply(check_answer, axis=1)\n",
    "\n",
    "    ref_tools = [\n",
    "#         ['[search]', '[check answer type]'],\n",
    "        ['[search]', '[check answer type]', '[compare]'], \n",
    "        ['[search]', '[check answer type]', '[Internal Knowledge]']\n",
    "    ]\n",
    "    tool_usage = collect_usage(df)\n",
    "    tool_use_acc = [jaccard_sim(each, ref_tools) for each in tool_usage]\n",
    "    bin_acc = {}\n",
    "    for i, b in enumerate(bin_indices):\n",
    "        which_bin = 0.1 * np.average([b-1, b])\n",
    "        if which_bin in bin_acc:\n",
    "            # tool use acc\n",
    "#             bin_acc[which_bin].append(tool_use_acc[i])\n",
    "            # qa acc\n",
    "            bin_acc[which_bin].append(df[\"adj_correct\"][i])\n",
    "        else:\n",
    "            # tool use acc\n",
    "#             bin_acc[which_bin] = [tool_use_acc[i]]\n",
    "            # qa acc\n",
    "            bin_acc[which_bin] = [df[\"adj_correct\"][i]]\n",
    "\n",
    "    # calculate ECE for each bin\n",
    "    ece = 0\n",
    "    for key in bin_acc:\n",
    "        ece += len(bin_acc[key]) / len(df) * np.abs(np.average(bin_acc[key]) - key)\n",
    "        \n",
    "        \n",
    "    print(f\"ECE for {f}: {format(ece, '.4f')}\\n\")\n",
    "\n",
    "#     for key in bin_acc:\n",
    "#         print(f\"bin: {key}, length: {len(bin_acc[key])}\")\n",
    "#         bin_acc[key] = np.average(bin_acc[key])\n",
    "#     print('\\n')\n",
    "\n",
    "    plt_data = sorted(bin_acc.items())\n",
    "    conf_range, acc = [int(100 * d[0]) for d in plt_data], [int(100*np.average(d[1])) for d in plt_data]\n",
    "    return conf_range, acc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b013ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file mintaka_ablation(dev)_gpt-3.5-turbo-0613_out.json...\n",
      "ECE for mintaka_ablation(dev)_gpt-3.5-turbo-0613_out.json: 0.2635\n",
      "\n",
      "[5, 55, 65, 75, 85] [18, 0, 25, 48, 58]\n",
      "Editing file mintaka_ablation_gpt-3.5-turbo-0613_out.json...\n",
      "Create an empty list in json file!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [03:33,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file mintaka_ablation(dev)_gpt-4_out.json...\n",
      "ECE for mintaka_ablation(dev)_gpt-4_out.json: 0.2100\n",
      "\n",
      "[55, 65, 75, 85] [100, 29, 64, 62]\n",
      "Editing file mintaka_ablation_gpt-4_out.json...\n",
      "Create an empty list in json file!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [03:40,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_files = [\n",
    "#     \"mintaka_(dev)_llama_3_70b_out.json\",\n",
    "#     \"pop_qa_(dev)_llama_3_70b_out.json\",\n",
    "#     \"entity_ques_(dev)_llama_3_70b_out.json\",\n",
    "#     \"pop_qa_(dev)_gpt-3.5-turbo-instruct-0914_out.json\",\n",
    "#     \"pop_qa_(dev)_gpt-3.5-turbo_out.json\",\n",
    "#     \"pop_qa_(dev)_gpt-4_out.json\",\n",
    "#     \"entity_ques_(dev)_gpt-3.5-turbo-instruct-0914_out.json\",\n",
    "#     \"whole_data_uncalibrated/entity_ques_1_gpt-3.5-turbo_out.json\",\n",
    "#     \"entity_ques_(dev)_gpt-4_out.json\",\n",
    "#     \"mintaka_(dev)_gpt-3.5-turbo-instruct-0914_out.json\",\n",
    "#     \"mintaka_(dev)_gpt-3.5-turbo_out.json\",\n",
    "#     \"mintaka_(dev)_gpt-4_out.json\",\n",
    "    \"mintaka_ablation(dev)_gpt-3.5-turbo-0613_out.json\",\n",
    "    \"mintaka_ablation(dev)_gpt-4_out.json\",\n",
    "    \n",
    "]\n",
    "\n",
    "files = [\n",
    "#     \"mintaka_(eval)_llama_3_70b_out.json\",\n",
    "#     \"pop_qa_(eval_v3.0)_llama_3_70b_out.json\",\n",
    "#     \"entity_ques_(eval)_llama_3_70b_out.json\",\n",
    "#     \"pop_qa_(eval)_gpt-3.5-turbo-instruct-0914_out.json\",\n",
    "#     \"pop_qa_(eval_v2.0)_gpt-3.5-turbo_out.json\",\n",
    "#     \"pop_qa_(eval_v3.0)_gpt-4_out.json\",\n",
    "#     \"entity_ques_(eval)_gpt-3.5-turbo-instruct-0914_out.json\",\n",
    "#     \"entity_ques_(eval)_gpt-3.5-turbo_out.json\",\n",
    "#     \"entity_ques_(eval)_gpt-4_out.json\",\n",
    "#     \"mintaka_(eval)_gpt-3.5-turbo-instruct-0914_out.json\",\n",
    "#     \"mintaka_(eval)_gpt-3.5-turbo_out.json\",\n",
    "#     \"mintaka_(eval_v2.0)_gpt-4_out.json\",\n",
    "    \"mintaka_ablation_gpt-3.5-turbo-0613_out.json\",\n",
    "    \"mintaka_ablation_gpt-4_out.json\",\n",
    "]\n",
    "\n",
    "for f1, f2 in zip(dev_files, files):\n",
    "    conf_range, acc_lst = collect_conf_acc(f1)\n",
    "    print(conf_range, acc_lst)\n",
    "    conf_edit(f2, conf_range, acc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b409b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
